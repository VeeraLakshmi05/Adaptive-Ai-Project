{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b02736-c713-4c31-b55a-25eed2ce58fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Google AI API key:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Adaptive AI Chat Started (type 'exit' to quit) ===\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  i am so stressful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜: Oh, my dear, I hear you. \"So stressful\" â€“ that sounds like a heavy weight you're carrying right now, and I'm so sorry you're feeling that way. It takes a lot to even say those words, and I want you to know I'm here to listen.\n",
      "\n",
      "Please, just take a moment. It's completely understandable to feel overwhelmed when stress builds up. You don't have to explain anything right away, just know that your feelings are valid, and it's okay to feel exactly what you're feeling. I'm here with you.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  because i have exam tomorrow and didnt start prepartion yet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜: Oh, my heart goes out to you. That's an incredibly tough spot to be in, my dear. Having an exam tomorrow and feeling like you haven't even begun to prepare... that's a recipe for immense pressure and a deep sense of panic. It's no wonder you're feeling so stressed.\n",
      "\n",
      "Anyone in your shoes would feel exactly the same way. That knot in your stomach, the racing thoughts, the feeling of being completely overwhelmed â€“ it's all a very natural response to such a daunting situation. Please, be kind to yourself for feeling this way. It's a heavy burden to carry, and I truly hear how much it's weighing on you right now.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  give some solutions to my problem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜: Oh, my dear, that's a truly overwhelming situation, and it's completely understandable why you're feeling so stressed. Let's focus on what you *can* do in this limited time. Here are four practical solutions to help you navigate this:\n",
      "\n",
      "1.  **Triage and Target Key Concepts:** Don't try to learn everything. Quickly scan your syllabus, notes, or textbook headings to identify the most crucial topics, definitions, or formulas. Focus your limited time on understanding the absolute core concepts that are most likely to appear, aiming for a basic grasp rather than deep mastery.\n",
      "\n",
      "2.  **Practice with Past Questions/Summaries:** Instead of reading entire chapters, try to find and work through a few past exam questions or review concise summaries. This active recall is far more efficient for last-minute learning, helping you identify what you *do* know and quickly pinpoint major gaps.\n",
      "\n",
      "3.  **Prioritize Strategic Rest:** While it feels counterintuitive, aim for at least 4-5 hours of sleep tonight. An exhausted brain struggles to recall information or think clearly during the exam. A little rest will make you more effective in the morning and during the test itself.\n",
      "\n",
      "4.  **Create a Micro-Study Plan:** Break down the remaining hours into very short, focused blocks (e.g., 30-minute bursts). Assign a specific, manageable task to each block, like \"review Chapter 2 summary\" or \"attempt 3 practice problems.\" Stick to this plan to build momentum and avoid feeling completely lost.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  give me 1 solution which is best\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜: Here is the single best solution for your situation:\n",
      "\n",
      "1.  **Focus intensely on past exam papers or concise summaries/review guides to identify and absorb the most frequently tested or critical concepts, prioritizing active recall over passive reading.** This strategy allows you to quickly pinpoint high-yield information and practice retrieving it, which is far more effective than trying to read entire chapters when time is critically short.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  give top 2 best solutions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜: Here are the top two best solutions for your situation:\n",
      "\n",
      "1.  **Prioritize High-Yield Content:** Immediately identify and focus on the most critical topics, definitions, formulas, or problem types that are most likely to appear on the exam. Use past papers, syllabus outlines, or chapter summaries to quickly pinpoint these \"high-yield\" areas, aiming for a basic understanding rather than deep mastery.\n",
      "\n",
      "2.  **Implement a Micro-Study Plan & Strategic Rest:** Break down your remaining time into very short, focused study blocks (e.g., 25-30 minutes) with short breaks. Crucially, ensure you get at least 4-5 hours of sleep tonight. An exhausted brain performs poorly, and even a little rest will significantly improve your ability to recall information and think clearly during the exam.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜: You are so very welcome, my dear. I truly hope these suggestions can offer a little bit of clarity and ease some of that immense pressure you're feeling.\n",
      "\n",
      "Remember, even in the most challenging moments, taking a deep breath and focusing on one small step at a time can make a difference. You're facing a tough situation with courage, and I'm sending you all my support.\n",
      "\n",
      "Please, be kind to yourself through this. You've got this.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ð—¨ð˜€ð—²ð—¿:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "import getpass\n",
    "import os\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load API Key\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "\n",
    "# ---------------------------- CLASSIFIER MODEL ---------------------------- #\n",
    "\n",
    "class MessageClassifier(BaseModel):\n",
    "    message_type: Literal[\"emotional\", \"logical\"]\n",
    "    solution_count: int\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    message_type: str | None\n",
    "    solution_count: int | None\n",
    "    next: str | None\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# ------------------ EXTRACT NUMBER OF SOLUTIONS ------------------ #\n",
    "\n",
    "def extract_solution_count(text: str) -> int:\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    number_map = {\n",
    "        \"one\": 1, \"1\": 1,\n",
    "        \"two\": 2, \"2\": 2,\n",
    "        \"three\": 3, \"3\": 3,\n",
    "        \"four\": 4, \"4\": 4,\n",
    "        \"five\": 5, \"5\": 5,\n",
    "        \"six\": 6, \"6\": 6,\n",
    "        \"seven\": 7, \"7\": 7,\n",
    "        \"eight\": 8, \"8\": 8,\n",
    "        \"nine\": 9, \"9\": 9,\n",
    "        \"ten\": 10, \"10\": 10\n",
    "    }\n",
    "\n",
    "    for word, val in number_map.items():\n",
    "        if word in text:\n",
    "            return min(val, 10)\n",
    "\n",
    "    m = re.search(r\"give me (\\d+)\", text)\n",
    "    if m:\n",
    "        return min(int(m.group(1)), 10)\n",
    "\n",
    "    if \"many\" in text:\n",
    "        return 6\n",
    "    if \"some\" in text:\n",
    "        return 4\n",
    "    if \"couple\" in text:\n",
    "        return 2\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "# ---------------------------- CLASSIFY NODE ---------------------------- #\n",
    "\n",
    "def classify_message(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    msg_text = last_message.content.lower()\n",
    "\n",
    "    sol_count = extract_solution_count(msg_text)\n",
    "\n",
    "    classifier_llm = llm.with_structured_output(MessageClassifier)\n",
    "\n",
    "    result = classifier_llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            Classify message as:\n",
    "            - emotional: feelings, stress, sadness, overwhelm.\n",
    "            - logical: when user directly asks for solutions.\n",
    "\n",
    "            If user asks for ANY number of solutions,\n",
    "            ALWAYS classify as logical.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": last_message.content}\n",
    "    ])\n",
    "\n",
    "    if sol_count > 0:\n",
    "        result.message_type = \"logical\"\n",
    "\n",
    "    return {\n",
    "        \"message_type\": result.message_type,\n",
    "        \"solution_count\": sol_count\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------- HISTORY BUILDER ---------------------------- #\n",
    "\n",
    "def build_history(state: State):\n",
    "    return [\n",
    "        {\"role\": msg.type, \"content\": msg.content}\n",
    "        for msg in state[\"messages\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "# ---------------------------- THERAPIST AGENT ---------------------------- #\n",
    "\n",
    "def therapist_agent(state: State):\n",
    "    history = build_history(state)\n",
    "\n",
    "    reply = llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are a compassionate therapist.\n",
    "            - Empathize deeply.\n",
    "            - Validate feelings.\n",
    "            - NO step-by-step logical solutions.\n",
    "            - Speak warmly, supportively.\n",
    "            \"\"\"\n",
    "        },\n",
    "        *history\n",
    "    ])\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}\n",
    "\n",
    "\n",
    "# ---------------------------- LOGICAL AGENT ---------------------------- #\n",
    "\n",
    "def logical_agent(state: State):\n",
    "    history = build_history(state)\n",
    "    sol_count = state.get(\"solution_count\", 0)\n",
    "\n",
    "    if sol_count <= 0:\n",
    "        sol_count = 1  # default\n",
    "\n",
    "    reply = llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are a logical assistant.\n",
    "\n",
    "            User requested EXACTLY {sol_count} solutions.\n",
    "            - Give exactly {sol_count} solutions.\n",
    "            - Each solution must be normal length (3â€“5 lines).\n",
    "            - Number them clearly 1, 2, 3...\n",
    "            - Be clear, practical, and helpful.\n",
    "            \"\"\"\n",
    "        },\n",
    "        *history\n",
    "    ])\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}\n",
    "\n",
    "\n",
    "# ---------------------------- ROUTER NODE ---------------------------- #\n",
    "\n",
    "def router(state: State):\n",
    "    return {\"next\": state[\"message_type\"]}\n",
    "\n",
    "\n",
    "# ---------------------------- GRAPH BUILD ---------------------------- #\n",
    "\n",
    "graph_builder.add_node(\"classify\", classify_message)\n",
    "graph_builder.add_node(\"therapist\", therapist_agent)\n",
    "graph_builder.add_node(\"logical\", logical_agent)\n",
    "graph_builder.add_node(\"router\", router)\n",
    "\n",
    "graph_builder.add_edge(START, \"classify\")\n",
    "graph_builder.add_edge(\"classify\", \"router\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda state: state[\"next\"],\n",
    "    {\n",
    "        \"emotional\": \"therapist\",\n",
    "        \"logical\": \"logical\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"therapist\", END)\n",
    "graph_builder.add_edge(\"logical\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "# ---------------------------- FINAL CHAT LOOP ---------------------------- #\n",
    "\n",
    "def run_chat():\n",
    "    state: State = {\n",
    "        \"messages\": [],\n",
    "        \"message_type\": None,\n",
    "        \"solution_count\": 0,\n",
    "        \"next\": None\n",
    "    }\n",
    "\n",
    "    user_label = \"ð—¨ð˜€ð—²ð—¿\"\n",
    "    assistant_label = \"ð—”ð˜€ð˜€ð—¶ð˜€ð˜ð—®ð—»ð˜\"\n",
    "\n",
    "    print(\"\\n=== Adaptive AI Chat Started (type 'exit' to quit) ===\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(f\"{user_label}: \").strip()\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nChat ended.\")\n",
    "            break\n",
    "\n",
    "        state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        state = graph.invoke(state)\n",
    "\n",
    "        assistant_message = state[\"messages\"][-1].content\n",
    "        print(f\"{assistant_label}: {assistant_message}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2209260-2925-4466-943f-8c6d8ba12031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\veera'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3285e-8f67-4f18-9719-46c814bcc348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
